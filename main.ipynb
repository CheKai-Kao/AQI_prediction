{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd973085",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, Subset, DataLoader\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e434415b",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd72c758",
   "metadata": {},
   "outputs": [],
   "source": [
    "from find_neighbors import get_station_neighbors\n",
    "\n",
    "\n",
    "class AQIDailyDataset(Dataset):\n",
    "    def __init__(self, raw_file_path, fpca_file_path, site_id, mode='train', valid_threshold=3):\n",
    "        super().__init__()\n",
    "        # 載入資料\n",
    "        raw_loaded = np.load(raw_file_path, allow_pickle=True)\n",
    "        fpca_loaded = np.load(fpca_file_path, allow_pickle=True)\n",
    "        \n",
    "        self.raw_data = raw_loaded['data']      # (5, 77, Day, 24)\n",
    "        self.stations = raw_loaded['stations']\n",
    "        self.dates = raw_loaded['dates']\n",
    "        #self.fpca_data = fpca_loaded['data']    # (77, Day, 24)\n",
    "        \n",
    "        # 目標測站\n",
    "        st_idx = np.where(self.stations == site_id)[0][0]\n",
    "        st_raw = self.raw_data[:, st_idx, :, :].transpose(1, 0, 2) # (Day, 5, 24)\n",
    "        \n",
    "        # u,v\n",
    "        wd_rad = np.deg2rad(st_raw[:, 0, :])\n",
    "        ws = st_raw[:, 1, :]\n",
    "        u, v = -ws * np.sin(wd_rad), -ws * np.cos(wd_rad)\n",
    "\n",
    "        # 輔助測站\n",
    "        neighbor_dict, pos_dict = get_station_neighbors(k=50)\n",
    "        \n",
    "        # 輔助測站 (PM2.5 Only)\n",
    "        nb_ids = neighbor_dict.get(site_id, [])\n",
    "        nb_indices = [np.where(self.stations == nid)[0][0] for nid in nb_ids if nid in self.stations]\n",
    "        nb_pm25 = self.raw_data[3, nb_indices, :, :].transpose(1, 0, 2) # (Day, num_nb, 24)\n",
    "        # 輔助測站，相對位置資訊\n",
    "        self.nb_pos = pos_dict.get(site_id, [])   # (num_nb, 3)\n",
    "        print(\"self.nb_pos\", self.nb_pos.shape)\n",
    "\n",
    "        # x: (Day, 5 + max_k, 24)\n",
    "        num_nb = len(nb_indices)\n",
    "        num_days = st_raw.shape[0]\n",
    "        self.data_all = np.full((num_days, 5+num_nb, 24), np.nan)   # (D, 5+num_nb, 24) 有nan\n",
    "        self.data_all[:, 0, :] = u / 15.0\n",
    "        self.data_all[:, 1, :] = v / 15.0\n",
    "        self.data_all[:, 2, :] = st_raw[:, 2, :] / 40.0\n",
    "        self.data_all[:, 3, :] = st_raw[:, 3, :] / 100.0 # Target PM2.5 Raw\n",
    "        self.data_all[:, 4, :] = st_raw[:, 4, :] / 100.0\n",
    "        if len(nb_indices) > 0:\n",
    "            self.data_all[:, 5:5+num_nb, :] = nb_pm25 / 100.0\n",
    "\n",
    "        # 時間座標處理\n",
    "        dt_dates = pd.to_datetime(self.dates)\n",
    "        self.day_coords = np.stack([\n",
    "            np.where(dt_dates.weekday.values >= 5, 1.0, 0.0),\n",
    "            np.sin(2 * np.pi * dt_dates.weekday.values / 7.0),\n",
    "            np.cos(2 * np.pi * dt_dates.weekday.values / 7.0),\n",
    "            np.sin(2 * np.pi * (dt_dates.month.values - 1) / 12.0),\n",
    "            np.cos(2 * np.pi * (dt_dates.month.values - 1) / 12.0)\n",
    "        ], axis=1) # (Day, 5)\n",
    "        \n",
    "        # 過濾有效索引\n",
    "        years = dt_dates.year.values\n",
    "        indices_pool = np.where(years < 2025)[0] if mode == 'train' else np.where(years == 2025)[0]\n",
    "        self.valid_indices = [\n",
    "            i for i in indices_pool if i+1 < num_days and \n",
    "            (~np.isnan(self.data_all[i, 3, :])).sum() > valid_threshold and\n",
    "            (~np.isnan(self.data_all[i+1, 3, :])).sum() > valid_threshold\n",
    "        ]\n",
    "\n",
    "        print( f\"data_tensor_shape: {self.data_all.shape}\")\n",
    "        print( f\"# of aux station: {num_nb}\")\n",
    "        print( f\"# of {mode} samples: {len(self.valid_indices)}\")\n",
    "\n",
    "    def __len__(self): return len(self.valid_indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        d_idx = self.valid_indices[idx]\n",
    "        \n",
    "        x_val = self.data_all[d_idx]\n",
    "        x_mask = (~np.isnan(x_val)).astype(np.float32)\n",
    "        \n",
    "        y_raw = self.data_all[d_idx+1, 3, :] \n",
    "        y_raw_mask = (~np.isnan(y_raw)).astype(np.float32) \n",
    "\n",
    "        other_y = self.data_all[d_idx+1, [0,1,2,4], :] \n",
    "        other_mask = (~np.isnan(other_y)).astype(np.float32) \n",
    "        \n",
    "        day_coord = self.day_coords[d_idx+1]\n",
    "        \n",
    "        return {\n",
    "            'x': torch.tensor(np.nan_to_num(x_val), dtype=torch.float32),\n",
    "            'x_mask': torch.tensor(x_mask, dtype=torch.float32),\n",
    "\n",
    "            'y_raw': torch.tensor(np.nan_to_num(y_raw), dtype=torch.float32),\n",
    "            'y_raw_mask': torch.tensor(y_raw_mask, dtype=torch.float32),\n",
    "\n",
    "            'other_y': torch.tensor(np.nan_to_num(other_y), dtype=torch.float32),\n",
    "            'other_mask': torch.tensor(other_mask, dtype=torch.float32),      \n",
    "               \n",
    "            'day_coord': torch.tensor(day_coord, dtype=torch.float32),\n",
    "            'aux_pos': torch.tensor(self.nb_pos, dtype=torch.float32)  # 鄰居相對位置資訊\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58151cc4",
   "metadata": {},
   "source": [
    "# DataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6760039d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AQIDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, raw_file_path: str, fpca_file_path: str, site_id: int, batch_size: int, valid_threshold=0.8):\n",
    "        super().__init__()\n",
    "        self.raw_file_path = raw_file_path\n",
    "        self.fpca_file_path = fpca_file_path\n",
    "        self.site_id = site_id\n",
    "        self.batch_size = batch_size\n",
    "        self.valid_threshold = valid_threshold\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            # 建立 2017-2024 的完整訓練數據集\n",
    "            full_train_dataset = AQIDailyDataset(\n",
    "                raw_file_path=self.raw_file_path,\n",
    "                fpca_file_path=self.fpca_file_path,\n",
    "                site_id=self.site_id, \n",
    "                mode='train', \n",
    "                valid_threshold=self.valid_threshold\n",
    "            )\n",
    "            num_samples = len(full_train_dataset)\n",
    "\n",
    "            train_size = int(num_samples * 0.8)\n",
    "            self.train_dataset = Subset(full_train_dataset, range(0, train_size)) \n",
    "            self.val_dataset = Subset(full_train_dataset, range(train_size, num_samples))  \n",
    " \n",
    "        if stage == \"test\" or stage is None:\n",
    "            # 建立 2025 的測試數據集\n",
    "            self.test_dataset = AQIDailyDataset(\n",
    "                raw_file_path=self.raw_file_path,\n",
    "                fpca_file_path=self.fpca_file_path,\n",
    "                site_id=self.site_id, \n",
    "                mode='test', \n",
    "                valid_threshold=self.valid_threshold\n",
    "            )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33aa98b0",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c2cc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AQIModelModule(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, model, site_id, lr=1e-3):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.lr = lr\n",
    "        self.site_id = site_id\n",
    "\n",
    "        self.test_outputs = []\n",
    "\n",
    "        self.site_dict_CH, self.site_dict_EN = self._build_siteid_to_name_dict(\"空氣品質監測站基本資料.csv\")\n",
    "        self.site_name_CH = self.site_dict_CH[site_id]\n",
    "        self.site_name_EN = self.site_dict_EN[site_id]\n",
    "\n",
    "    def _build_siteid_to_name_dict(self, csv_path: str):\n",
    "        df = pd.read_csv(csv_path)\n",
    "        df[\"siteid\"] = df[\"siteid\"].astype(int)\n",
    "        site_dict_CH = dict(zip(df[\"siteid\"], df[\"sitename\"]))\n",
    "        site_dict_EN = dict(zip(df[\"siteid\"], df[\"siteengname\"]))\n",
    "        return site_dict_CH, site_dict_EN\n",
    "\n",
    "    def forward(self, x, x_mask, day_coord, aux_pos):\n",
    "        return self.model(x, x_mask, day_coord, aux_pos)\n",
    "\n",
    "    def _common_step(self, batch, stage: str):\n",
    "        x = batch['x']\n",
    "        x_mask = batch['x_mask']\n",
    "\n",
    "        y_raw = batch['y_raw']\n",
    "        y_raw_mask = batch['y_raw_mask']\n",
    "\n",
    "        day_coord = batch['day_coord']\n",
    "        aux_pos = batch['aux_pos']\n",
    "\n",
    "        y_hat = self(x, x_mask, day_coord, aux_pos)\n",
    "\n",
    "        loss = (F.mse_loss(y_hat, y_raw, reduction='none') * y_raw_mask).sum() / (y_raw_mask.sum() + 1e-8)\n",
    "\n",
    "        y_real = y_raw * 100.0\n",
    "        y_hat = y_hat * 100.0\n",
    "\n",
    "        mse = (F.mse_loss(y_hat, y_real, reduction='none') * y_raw_mask).sum() / (y_raw_mask.sum() + 1e-8)\n",
    "        mae = (torch.abs(y_hat - y_real) * y_raw_mask).sum() / (y_raw_mask.sum() + 1e-8)\n",
    "\n",
    "        if stage != \"train\":\n",
    "            self.log_dict({f\"{stage}/mse\": mse, f\"{stage}/mae\": mae}, prog_bar=True)\n",
    "\n",
    "        return {\n",
    "            \"loss\": loss,\n",
    "            \"mse\": mse,\n",
    "            \"mae\": mae,\n",
    "            \"y_hat\": y_hat,\n",
    "            \"y_real\": y_real,\n",
    "            \"mask\": y_raw_mask\n",
    "        }\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        out = self._common_step(batch, \"train\")\n",
    "        self.log(\"train/loss\", out[\"loss\"], prog_bar=True)\n",
    "        return out[\"loss\"]\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        self._common_step(batch, \"val\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        out = self._common_step(batch, \"test\")\n",
    "\n",
    "        self.test_outputs.append({\n",
    "            'y_real': out[\"y_real\"].cpu().numpy(),\n",
    "            'y_hat': out[\"y_hat\"].cpu().numpy(),\n",
    "            'mask': out[\"mask\"].cpu().numpy()\n",
    "        })\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "\n",
    "        all_y = np.concatenate([x['y_real'] for x in self.test_outputs], axis=0)\n",
    "        all_y_hat = np.concatenate([x['y_hat'] for x in self.test_outputs], axis=0)\n",
    "        all_mask = np.concatenate([x['mask'] for x in self.test_outputs], axis=0)\n",
    "\n",
    "        flat_y = all_y[all_mask == 1]\n",
    "        flat_y_hat = all_y_hat[all_mask == 1]\n",
    "\n",
    "        overall_mse = mean_squared_error(flat_y, flat_y_hat)\n",
    "        overall_mae = mean_absolute_error(flat_y, flat_y_hat)\n",
    "        overall_r2 = r2_score(flat_y, flat_y_hat)\n",
    "\n",
    "        hourly_r2 = []\n",
    "        for h in range(24):\n",
    "            h_y = all_y[:, h]\n",
    "            h_y_hat = all_y_hat[:, h]\n",
    "            h_mask = all_mask[:, h]\n",
    "\n",
    "            valid_h_y = h_y[h_mask == 1]\n",
    "            valid_h_y_hat = h_y_hat[h_mask == 1]\n",
    "\n",
    "            hourly_r2.append(r2_score(valid_h_y, valid_h_y_hat) if len(valid_h_y) > 1 else 0)\n",
    "\n",
    "        self._plot_hourly_r2(hourly_r2, overall_mse, overall_r2)\n",
    "\n",
    "        self.log(\"test/mse\", overall_mse)\n",
    "        self.log(\"test/mae\", overall_mae)\n",
    "        self.log(\"test/r2\", overall_r2)\n",
    "\n",
    "        self.test_outputs.clear()\n",
    "\n",
    "    def _plot_hourly_r2(self, hourly_r2, overall_mse, overall_r2):\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(range(24), hourly_r2, marker='o', linestyle='-', color='b')\n",
    "\n",
    "        title_str = (\n",
    "            f'Hourly $R^2$ of {self.site_name_EN} (Test Set 2025)\\n'\n",
    "            f'Overall MSE: {overall_mse:.2f}, Overall $R^2$: {overall_r2:.4f}'\n",
    "        )\n",
    "\n",
    "        plt.title(title_str, fontsize=14)\n",
    "        plt.xlabel('Hour of Day')\n",
    "        plt.ylabel('R^2 Score')\n",
    "        plt.grid(True)\n",
    "        plt.xticks(range(24))\n",
    "        plt.ylim([-0.1, 1])\n",
    "\n",
    "        os.makedirs(f'results/{result_folder}', exist_ok=True)\n",
    "        plt.savefig(f'results/{result_folder}/hourly_r2_sid_{self.site_id}_{self.site_name_CH}.png')\n",
    "        plt.close()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026fdc1c",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c453f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from iTransformer_Entmax import iTransformer_Entmax\n",
    "\n",
    "\n",
    "raw_file_path = 'aqi_data.npz'\n",
    "fpca_file_path = 'after_fpca_PM2.5.npz'\n",
    "\n",
    "offline = False\n",
    "\n",
    "batch_size = 1024\n",
    "max_epochs = 300\n",
    "\n",
    "wandb_project = \"iTransformer\"\n",
    "subname = \"date+auxst+pos+Entmax+NOlayernorm\"\n",
    "result_folder = f\"{wandb_project}_{subname}\"\n",
    "\n",
    "pl.seed_everything(42)  # 固定種子\n",
    "\n",
    "loaded = np.load(raw_file_path, allow_pickle=True)\n",
    "all_stations = loaded['stations']\n",
    "\n",
    "all_station_results = []\n",
    "\n",
    "for sid in all_stations:\n",
    "\n",
    "    if sid != 19:\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n{'='*30}\\nStarting Station: {sid}\\n{'='*30}\")\n",
    "    \n",
    "    wandb_logger = WandbLogger(\n",
    "        project=wandb_project,\n",
    "        name=f\"Station_{sid}/{subname}\",\n",
    "        save_dir=\"logs\",\n",
    "        offline=offline,\n",
    "        group=f\"Station_{sid}\"\n",
    "    )\n",
    "    \n",
    "    dm = AQIDataModule(\n",
    "        raw_file_path=raw_file_path,\n",
    "        fpca_file_path=fpca_file_path,\n",
    "        site_id=sid,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    \n",
    "    base_model = iTransformer_Entmax(\n",
    "    # [U, V, Temp, PM2.5, Hum, num_nb, timestamp]\n",
    "        lookback_len=24, \n",
    "        d_model=128, \n",
    "        n_heads=8,\n",
    "        e_layers=3,\n",
    "        dropout=0.2\n",
    "    )\n",
    "    \n",
    "    model = AQIModelModule(\n",
    "        model=base_model, \n",
    "        site_id=sid,  \n",
    "        lr=1e-3\n",
    "    )\n",
    "    \n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor=\"val/mse\",\n",
    "        dirpath=f\"checkpoints/{result_folder}/station_{sid}\",\n",
    "        filename=f\"siteID_{sid}_best-model\",\n",
    "        save_top_k=1,\n",
    "        mode=\"min\",\n",
    "    )\n",
    "    \n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator=\"auto\", \n",
    "        devices=1,\n",
    "        logger=wandb_logger,\n",
    "        callbacks=[checkpoint_callback],\n",
    "        log_every_n_steps=10\n",
    "    )\n",
    "    \n",
    "    trainer.fit(model, datamodule=dm)\n",
    "\n",
    "    test_result = trainer.test(model, datamodule=dm, ckpt_path=\"best\")\n",
    "\n",
    "\n",
    "    if test_result and len(test_result) > 0:\n",
    "            all_station_results.append({\n",
    "                'sid': sid,\n",
    "                'mse': test_result[0][\"test/mse\"],\n",
    "                'mae': test_result[0][\"test/mae\"],\n",
    "                'r2':  test_result[0][\"test/r2\"]\n",
    "            })\n",
    "    \n",
    "    wandb_logger.experiment.finish()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "if all_station_results:\n",
    "    sids = np.array([str(r['sid']) for r in all_station_results])\n",
    "    mses = np.array([r['mse'] for r in all_station_results])\n",
    "    maes = np.array([r['mae'] for r in all_station_results])\n",
    "    r2s  = np.array([r['r2'] for r in all_station_results])\n",
    "\n",
    "    avg_mse, avg_mae, avg_r2 = np.mean(mses), np.mean(maes), np.mean(r2s)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(20, 14))\n",
    "    fig.suptitle(f\"Global Evaluation Report: 77 Stations (2025 Test Set)\", fontsize=22, fontweight='bold')\n",
    "\n",
    "    # --- A. 繪製 MSE (由小到大排序) ---\n",
    "    idx_mse = np.argsort(mses)\n",
    "    ax1.bar(sids[idx_mse], mses[idx_mse], color='salmon', edgecolor='darkred', alpha=0.8)\n",
    "    ax1.axhline(avg_mse, color='blue', linestyle='--', linewidth=2, label=f'Grand Mean MSE: {avg_mse:.2f}')\n",
    "    ax1.set_title(\"MSE per Station (Lower is Better)\", fontsize=16)\n",
    "    ax1.set_ylabel(\"MSE\", fontsize=12)\n",
    "    ax1.tick_params(axis='x', rotation=90, labelsize=9)\n",
    "    ax1.legend()\n",
    "\n",
    "    # --- B. 繪製 R2 (由大到小排序) ---\n",
    "    idx_r2 = np.argsort(r2s)[::-1] # 降序排列\n",
    "    ax2.bar(sids[idx_r2], r2s[idx_r2], color='skyblue', edgecolor='navy', alpha=0.8)\n",
    "    ax2.axhline(avg_r2, color='red', linestyle='--', linewidth=2, label=f'Grand Mean R²: {avg_r2:.2f}')\n",
    "    ax2.set_title(\"R² Score per Station (Higher is Better)\", fontsize=16)\n",
    "    ax2.set_ylabel(\"R² Score\", fontsize=12)\n",
    "    ax2.set_ylim(0, 1)\n",
    "    ax2.tick_params(axis='x', rotation=90, labelsize=9)\n",
    "    ax2.legend()\n",
    "\n",
    "    stats_text = (f\"Grand Mean Summary\\n\"\n",
    "              f\"{'='*22}\\n\"\n",
    "              f\"Avg MSE: {avg_mse:.4f}\\n\"\n",
    "              f\"Avg MAE: {avg_mae:.4f}\\n\"\n",
    "              f\"Avg R² : {avg_r2:.4f}\")\n",
    "\n",
    "    fig.text(\n",
    "        0.02, 0.5, stats_text,\n",
    "        fontsize=18, family='monospace',\n",
    "        bbox=dict(boxstyle='round', facecolor='white', edgecolor='black', alpha=0.95, pad=0.6),\n",
    "        verticalalignment='center'\n",
    "    )\n",
    "    plt.tight_layout(rect=[0.08, 0.03, 1, 0.95]) \n",
    "    \n",
    "    os.makedirs(f'results/{result_folder}', exist_ok=True)\n",
    "    save_path = f'results/{result_folder}/global_comprehensive_report.png'\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"\\n✅ 雙指標評估報告已儲存至: {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myPytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
